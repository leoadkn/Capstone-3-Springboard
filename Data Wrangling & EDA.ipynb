{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accdc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7211ebf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/reviews.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load data from a JSON file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/reviews.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(line))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/reviews.json'"
     ]
    }
   ],
   "source": [
    "# Load data from a JSON file\n",
    "data = []\n",
    "with open('Data/reviews.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe01e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into a pandas DataFrame\n",
    "df=pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names in the DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be94563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954df253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ba805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae2dce",
   "metadata": {},
   "source": [
    "# Overview of the data\n",
    "\n",
    "### Columns:\n",
    "  - `reviewerID`: Unique ID for the reviewer\n",
    "  - `asin`: Amazon Standard Identification Number, a unique code for the product\n",
    "  - `reviewerName`: Name of the reviewer\n",
    "  - `helpful`: Array indicating [number of helpful votes, total votes]\n",
    "  - `reviewText`: Text of the review\n",
    "  - `overall`: Rating given by the reviewer\n",
    "  - `summary`: Short summary of the review\n",
    "  - `unixReviewTime`: Time of the review in UNIX timestamp format\n",
    "  - `reviewTime`: Human-readable review time\n",
    "\n",
    "### Summary Statistics:\n",
    "- **Data Counts**: 194439 entries\n",
    "- **Missing Data**: There are 3519 review without reviewer names.\n",
    "- **Overall Ratings**: Ratings range from 1 to 5, with an average of approximately 4.12.\n",
    "\n",
    "### Next Steps for Data Wrangling and EDA:\n",
    "1. **Data Cleaning**:\n",
    "   - Address missing values where necessary\n",
    "   - Convert the `helpful` column to a more usable integer column for analysis.\n",
    "   - Convert `unixReviewTime` to a more readable date format.\n",
    "\n",
    "2. **Exploratory Data Analysis (EDA)**:\n",
    "   - Distribution of ratings (`overall`).\n",
    "   - Trends over time (using `reviewTime`).\n",
    "   - Text analysis of `reviewText` and `summary` for common themes.\n",
    "   - Analysis of helpfulness ratings to see how they correlate with review ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and data type conversions\n",
    "df['reviewerName'].fillna('Unknown', inplace=True)\n",
    "df['reviewerName'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['helpful'] = df['helpful'].astype(str)\n",
    "df[['helpful_votes', 'total_votes']] = df['helpful'].str.extract(r'\\[(\\d+), (\\d+)\\]')\n",
    "df[['helpful_votes', 'total_votes']] = df[['helpful_votes', 'total_votes']].fillna(0)\n",
    "df[['helpful_votes', 'total_votes']] = df[['helpful_votes', 'total_votes']].astype(int)\n",
    "df['helpfulness_score'] = np.where(df['total_votes'] > 0, \n",
    "                                     (df['helpful_votes'] / df['total_votes']) * 100, \n",
    "                                     np.nan)\n",
    "df['helpfulness_score'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewDate'] = pd.to_datetime(df['unixReviewTime'], unit='s')\n",
    "df['reviewDate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up DataFrame by dropping unnecessary columns\n",
    "df.drop(['helpful','helpful_votes','total_votes','unixReviewTime','reviewTime'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc880152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'rating' based on the 'overall' column to classify reviews\n",
    "df['rating'] = ''  \n",
    "df.loc[df['overall'] >= 3, 'rating'] = 'Good'\n",
    "df.loc[df['overall'] <= 3, 'rating'] = 'Bad'\n",
    "df.loc[df['overall'] == 3, 'rating'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the percentage distribution of ratings\n",
    "rating_counts = df['rating'].value_counts()\n",
    "rating_percent = (rating_counts / rating_counts.sum()) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=rating_percent.index, y=rating_percent.values)\n",
    "plt.title('Percentage Histogram of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the helpfulness scores\n",
    "custom_bins = [0, 1, 40, 60, 100]\n",
    "custom_labels =['Null (0%)', 'Low (1-40%)', 'Medium (41-60%)', 'High (61-100%)']\n",
    "helpfulness_data = df['helpfulness_score']\n",
    "helpfulness_categories = pd.cut(helpfulness_data, bins=custom_bins, labels=custom_labels, right=False)\n",
    "helpfulness_grouped_counts = helpfulness_categories.value_counts(sort=False)\n",
    "helpfulness_grouped_percent = (helpfulness_grouped_counts / helpfulness_grouped_counts.sum()) * 100\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_plot = sns.barplot(x=helpfulness_grouped_percent.index, y=helpfulness_grouped_percent.values)\n",
    "plt.title('Grouped Percentage Histogram of Helpfulness Scores')\n",
    "plt.xlabel('Helpfulness Score Group')\n",
    "plt.ylabel('Percentage (%)')\n",
    "for bar in bar_plot.patches:\n",
    "    bar_plot.annotate(format(bar.get_height(), '.2f') + '%', \n",
    "                      (bar.get_x() + bar.get_width() / 2, \n",
    "                       bar.get_height()), ha='center', va='center',\n",
    "                       size=9, xytext=(0, 8),\n",
    "                       textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7ec66",
   "metadata": {},
   "source": [
    "### 1. Percentage Histogram of Ratings (Overall)\n",
    "This graph shows the distribution of ratings given by users on a scale of 1 to 5:\n",
    "\n",
    "- **High Ratings Dominance:** A significant portion of the ratings are 4s and 5s, with these two categories combined making up a large majority of all ratings. This suggests that users are generally satisfied with the products they are reviewing.\n",
    "- **Positive Skew:** The distribution of ratings is positively skewed, meaning that there are fewer low ratings (1s and 2s) compared to higher ratings. This could indicate that customers who decide to leave reviews are typically those who have had a positive experience, or it might reflect a generally good quality of products being reviewed.\n",
    "- **Few Neutral and Negative Ratings:** The relatively low percentages for ratings of 3 (neutral) and particularly 1 and 2 (negative) suggest that negative experiences are less common, or users are less inclined to leave reviews following mediocre or poor experiences.\n",
    "\n",
    "### 2. Percentage Histogram of Helpfulness Scores\n",
    "This graph represents how helpful others found the reviews, on a scale from 0% to 100%:\n",
    "\n",
    "- **High Helpfulness Scores:** There is a significant concentration of scores at 100%, indicating that many reviews are found completely helpful by those who rate them. This might suggest that reviewers are generally doing a good job of providing useful, clear, and thorough information about the products.\n",
    "- **Distribution Across Scores:** Aside from the peak at 100%, the rest of the scores are distributed across the range, but with notably smaller percentages. This shows that while many reviews are highly valued, there are still a number of reviews that receive mixed evaluations on their helpfulness.\n",
    "- **Low Helpfulness Less Common:** Lower helpfulness scores are notably less common, which could suggest that negative feedback on review helpfulness is relatively rare, or it could reflect a tendency of users to engage more with content they find useful, ignoring less helpful reviews.\n",
    "\n",
    "### Overall Insight\n",
    "Both graphs together give a picture of a community where positive sentiment in product reviews dominates and the reviews are frequently found helpful. This could be beneficial for potential buyers relying on these reviews to make purchasing decisions, as it suggests they are likely to encounter helpful and positive evaluations of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f115a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot monthly averages for ratings and helpfulness scores from review data\n",
    "monthly_avg_ratings = df.groupby(df['reviewDate'].dt.to_period(\"M\"))['overall'].mean().reset_index()\n",
    "monthly_avg_helpfulness = df.groupby(df['reviewDate'].dt.to_period(\"M\"))['helpfulness_score'].mean().reset_index()\n",
    "monthly_avg_ratings.rename(columns={'reviewDate': 'Month', 'overall': 'Average Rating'}, inplace=True)\n",
    "monthly_avg_helpfulness.rename(columns={'reviewDate': 'Month', 'helpfulness_score': 'Average Helpfulness Score'}, inplace=True)\n",
    "monthly_avg_ratings['Month'] = monthly_avg_ratings['Month'].dt.to_timestamp()\n",
    "monthly_avg_helpfulness['Month'] = monthly_avg_helpfulness['Month'].dt.to_timestamp()\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax[0].plot(monthly_avg_ratings['Month'], monthly_avg_ratings['Average Rating'], 'b-o', label='Average Rating')\n",
    "ax[0].set_title('Monthly Average Ratings')\n",
    "ax[0].set_xlabel('Month')\n",
    "ax[0].set_ylabel('Average Rating')\n",
    "ax[0].grid(True)\n",
    "ax[0].tick_params(axis='x', rotation=45)\n",
    "ax[1].plot(monthly_avg_helpfulness['Month'], monthly_avg_helpfulness['Average Helpfulness Score'], 'r-x', label='Average Helpfulness Score')\n",
    "ax[1].set_title('Monthly Average Helpfulness Scores')\n",
    "ax[1].set_xlabel('Month')\n",
    "ax[1].set_ylabel('Average Helpfulness Score')\n",
    "ax[1].grid(True)\n",
    "ax[1].tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean review text for text analysis\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_reviewText'] = df['reviewText'].astype(str).apply(clean_text)\n",
    "df['cleaned_summary'] = df['summary'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54561c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning function and generate word clouds\n",
    "all_reviews = ' '.join(df['cleaned_reviewText'])\n",
    "wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(all_reviews)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ced69",
   "metadata": {},
   "source": [
    "1. **Positive Sentiment**: Words like \"great,\" \"love,\" \"good,\" and \"nice\" appear prominently, indicating a generally positive sentiment among the reviews. This suggests that many customers are satisfied with their purchases.\n",
    "\n",
    "2. **Product Attributes**: Specific terms like \"case,\" \"screen,\" \"phone,\" and \"cover\" are also visible. This highlights that the reviews are focused on products related to mobile phones or similar devices.\n",
    "\n",
    "3. **Quality and Functionality**: Words such as \"perfect,\" \"easy,\" and \"well\" suggest that reviewers often comment on the quality and functionality of the products. They are likely appreciating how well the products meet their needs or how easy they are to use.\n",
    "\n",
    "4. **Emphasis on Aesthetics**: The presence of words like \"cute\" and \"pretty\" implies that aesthetic qualities are significant to reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de1035",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate and display word clouds for each rating category ('Good', 'Neutral', 'Bad') based on review summaries\n",
    "df['rating_category'] = pd.cut(df['overall'], bins=[0, 2, 3, 5], labels=['Bad', 'Neutral', 'Good'])\n",
    "rating_categories = ['Good', 'Neutral', 'Bad']\n",
    "fig, axes = plt.subplots(nrows=len(rating_categories), ncols=1, figsize=(10, 15))\n",
    "for i, category in enumerate(rating_categories):\n",
    "    specific_summaries = df[df['rating_category'] == category]['cleaned_summary']\n",
    "    combined_text = ' '.join(specific_summaries)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_text)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f'Word Cloud for {category} Ratings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only 'Neutral' and 'Bad' ratings where summaries contain the specified words\n",
    "pattern = r'\\b(good|great|work)\\b'\n",
    "filtered_data = df[\n",
    "    (df['rating_category'].isin(['Neutral', 'Bad'])) &\n",
    "    (df['cleaned_summary'].str.contains(pattern, case=False, regex=True))\n",
    "]\n",
    "\n",
    "# Sample a subset of the filtered data for inspection\n",
    "sample_data = filtered_data.sample(n=20, random_state=1)  # Random state for reproducibility\n",
    "\n",
    "sample_data[['reviewerID', 'overall', 'rating_category', 'summary', 'cleaned_summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da5287",
   "metadata": {},
   "source": [
    "Reviewing the sample data where 'Neutral' and 'Bad' ratings include summaries with generally positive words like 'good', 'great', or 'work', there are a few interesting observations that might seem unusual:\n",
    "\n",
    "1. **Positive Words in Negative Contexts**: Some summaries use positive words in a context that's not entirely positive. For example:\n",
    "   - \"Did not work\" uses \"work\" but in a negative sense.\n",
    "   - \"Not a good product.\" contains \"good\" but negates it.\n",
    "\n",
    "2. **Misalignment of Rating and Sentiment**: There are summaries where the sentiment expressed seems more positive than the rating would suggest:\n",
    "   - \"Works Well if Done Properly the FIRST Time\" and \"Works great\" are associated with a 'Neutral' rating (3.0), which might indicate some underlying issues.\n",
    "   - \"A good basic belt holster for the price.\" and \"Great Protection, Pain to Keep Clean\" also carry 'Neutral' ratings but contain positive descriptors like \"good\" and \"great\".\n",
    "\n",
    "3. **Ambiguity**: Some reviews might contain ambiguities that make them difficult to categorize strictly as positive or negative based only on a few keywords:\n",
    "   - \"Worked for a very short while\" suggests a temporary satisfaction which quickly turned unsatisfactory.\n",
    "   \n",
    "To improve the reflectiveness of word clouds, especially when dealing with reviews that contain positive words in negative contexts we will use Bigram or Trigram Analysis instead of using single words (unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44638ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram_wordcloud(data, title):\n",
    "    count_vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')\n",
    "    count_data = count_vectorizer.fit_transform(data)\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    total_counts = count_data.sum(axis=0)\n",
    "    freqs = {word: total_counts[0, idx] for word, idx in zip(words, total_counts.nonzero()[1])}\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freqs)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "generate_bigram_wordcloud(df[df['rating_category'] == 'Good']['cleaned_summary'], 'Bigram Word Cloud for Good Ratings')\n",
    "generate_bigram_wordcloud(df[df['rating_category'] == 'Neutral']['cleaned_summary'], 'Bigram Word Cloud for Neutral Ratings')\n",
    "generate_bigram_wordcloud(df[df['rating_category'] == 'Bad']['cleaned_summary'], 'Bigram Word Cloud for Bad Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760a882",
   "metadata": {},
   "source": [
    "### Conclusion on Word Cloud Analysis with Bigrams\n",
    "\n",
    "The use of bigram word clouds in analyzing the review summaries for different rating categories ('Good', 'Neutral', 'Bad') offered a deeper understanding of how certain phrases are commonly used within each context:\n",
    "\n",
    "1. **Contextual Nuance**: Bigram analysis helped capture the context around keywords which single-word analysis might miss. This was particularly insightful for identifying how positive words like \"good\" and \"great\" are used even in 'Neutral' and 'Bad' reviews, often in more complex phrases that convey dissatisfaction or conditional praise.\n",
    "\n",
    "2. **Identifying Trends**: The bigrams such as \"not good\" in 'Bad' reviews or \"works great\" in 'Neutral' reviews revealed a more detailed sentiment than could be gauged from single words alone. This indicates that while a product may generally meet expectations, it might still not fully satisfy users, leading to a neutral rating.\n",
    "\n",
    "3. **Sentiment Discrepancies**: The analysis also highlighted discrepancies where the sentiment implied by the summary text did not always align with the numerical rating. For example, relatively positive phrases in 'Neutral' ratings suggest that users acknowledge some positive aspects but might have reservations that prevent a fully positive rating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
